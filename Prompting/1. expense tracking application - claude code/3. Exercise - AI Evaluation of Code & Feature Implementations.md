## Prerequisites

- Completed Tutorial 2.2 (Best-of-N Pattern implementation)
- Three different implementations of data export feature in separate git branches
- Basic understanding of code evaluation principles
- Claude Code installed and working

## Part 1: Why Code Evaluation Matters for AI Development

### The Evaluation Challenge

When working with AI labor, you'll often have multiple working solutions to choose from. Unlike traditional development where you typically only build one version, AI's speed enables exploring multiple approaches. But this creates a new challenge: **How do you systematically evaluate and compare different implementations?**

### Traditional vs. AI Development Evaluation

**Traditional Development:**

- Evaluate one solution against theoretical alternatives
- Make decisions based on experience and intuition
- Limited ability to test different approaches
- High cost to change direction

**AI Development:**

- Evaluate multiple working implementations
- Compare real code, not theoretical approaches
- Test actual user experiences side-by-side
- Make data-driven decisions about architecture

### What We're Evaluating

In this tutorial, we'll evaluate three different implementations of the same feature across multiple dimensions.

## Part 2: Setting Up for Systematic Evaluation

### Step 1: Verify Your Implementations

First, let's make sure you have all three versions from Tutorial 2.2:
```
cd expense-tracker-ai
git branch -a
```
You should see:

- main
- feature-data-export-v1 (Simple CSV export)
- feature-data-export-v2 (Advanced export with options)
- feature-data-export-v3 (Cloud integration features)

### Step 2: Launch Claude Code

claude

### Step 3: Create & Execute the Evaluation

Now let's have Claude systematically examine each implementation by switching between branches and analyzing the code architecture, user interface design, and technical approaches used in each version. This systematic code review will help us understand not just what each version does, but how it accomplishes its goals and what trade-offs were made in the implementation.

We'll document our findings in a structured format that covers the technical architecture, code organization, libraries used, and implementation patterns for each version. This analysis will form the foundation for making informed decisions about which approach to adopt or how to combine the best elements from multiple versions.

**Prompt for Evaluation:**
```
I have three different implementations of data export functionality across three git branches in my expense tracker application. I want to create a systematic evaluation framework to compare them thoroughly.

BACKGROUND:
- feature-data-export-v1: Simple CSV export (one-button approach)
- feature-data-export-v2: Advanced export with multiple formats and filtering options
- feature-data-export-v3: Cloud integration with sharing and collaboration features

Now I want you to systematically analyze each of three features implementations by switching between branches and examining the code, architecture, and implementation details.

ANALYSIS PROCESS:
For each branch (v1, v2, v3), please:

1. Switch to the branch
2. Examine all the files that were created or modified
3. Analyze the code architecture and patterns used
4. Look at component structure and organization
5. Review the user interface implementation
6. Check for error handling and edge cases
7. Assess the technical approach and libraries used

DOCUMENTATION:
Create a file called "code-analysis.md" with detailed findings for each version:

**For Each Version, Document:**
- Files created/modified (list them)
- Code architecture overview (how is it organized?)
- Key components and their responsibilities
- Libraries and dependencies used
- Implementation patterns and approaches
- Code complexity assessment
- Error handling approach
- Security considerations
- Performance implications
- Extensibility and maintainability factors

**Technical Deep Dive:**
- How does the export functionality work technically?
- What file generation approach is used?
- How is user interaction handled?
- What state management patterns are used?
- How are edge cases handled?

Be thorough and technical - this analysis will inform our decision about which approach to adopt or how to combine them.
```